{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/credit/Credit.csv')\n\n# Display the dataset before standardization\nprint(\"Dataset before standardization:\")\nprint(df.head())\n\n# Select only the numeric columns for standardization (excluding target or categorical columns if any)\nnumeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n\n# Initialize the StandardScaler\nscaler = StandardScaler()\n\n# Standardize the numeric columns\ndf[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n\n# Display the dataset after standardization\nprint(\"\\nDataset after standardization:\")\nprint(df.head())\n\ntarget_column = 'Class'\n\n# Prepare features (X) and target (y)\nX = df.drop(columns=[target_column])  # Features\ny = df[target_column]                  # Target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n\nk_values = [1, 3, 5, 10]\n\n# Train and test the KNN model for each K value\nfor k in k_values:\n    # Initialize the KNN classifier\n    knn = KNeighborsClassifier(n_neighbors=k)\n    \n    # Train the model\n    knn.fit(X_train, y_train)\n    \n    # Predict on the test set\n    y_pred = knn.predict(X_test)\n    \n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    \n    # Calculate True Positive Rate (TPR) and False Negative Rate (FNR)\n    TP = conf_matrix[1, 1]  # True Positives\n    FN = conf_matrix[1, 0]  # False Negatives\n    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # True Positive Rate\n    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0  # False Negative Rate\n    \n    # Print confusion matrix and classification report\n    print(f\"\\nConfusion Matrix for K={k}:\")\n    print(conf_matrix)\n    \n    print(f\"\\nClassification Report for K={k}:\")\n    print(classification_report(y_test, y_pred))\n\n    # Include TPR and FNR in the output\n    print(f\"True Positive Rate for K={k}: {TPR:.4f}\")\n    print(f\"False Negative Rate for K={k}: {FNR:.4f}\")\n\n    # ROC Curve analysis\n    y_prob = knn.predict_proba(X_test)[:, 1]  # Probability estimates for the positive class\n    fpr, tpr, thresholds = roc_curve(y_test.apply(lambda x: 1 if x == 'Good' else 0), y_prob)\n    roc_auc = auc(fpr, tpr)\n\n    # Plot ROC Curve\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve for K={k} (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve for K={k}')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}